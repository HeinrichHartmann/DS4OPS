{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praxis 3: Regressions and Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "RATES = np.loadtxt(\"../datasets/request_rate_cluster:6h@5M.csv\",delimiter=\",\",skiprows=1)\n",
    "T = RATES[:,0]\n",
    "X = RATES[:,1]\n",
    "Y = RATES[:,2]\n",
    "Z = RATES[:,3].copy()\n",
    "np.random.shuffle(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plot a histogram of X,Y,Z. How do the distributions compare?\n",
    "\n",
    "2. Plot a scatter plot of:  \n",
    "   a) T,X  \n",
    "   b) X,Y  \n",
    "   c) X,Z  \n",
    "\n",
    "3. Use `linregress` to compute linear regression of (a) T,X (b) X,Y and(c) X,Z.\n",
    "   - Plot the resultint linear models\n",
    "   - What do the correlation coefficients tell you?\n",
    "     - Does t allow you to predict x?\n",
    "     - Does x allow you to predict y?\n",
    "     - Does x allow you to predict z?\n",
    "\n",
    "\n",
    "4. Do the same for the subslice [620:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For f and data defined in the next cell:\n",
    "\n",
    "1. Produce a scatter plot of the data\n",
    "\n",
    "2. Choose some example values for a,b,c, and produce a line plot of the model\n",
    "\n",
    "3.  Use `curve_fit` from `scipy.optimize` to find the paramters a,b,c that fit the data best.\n",
    "\n",
    "4. Produce a plot containing a scatter plot of the data and a line plot of the fitted model\n",
    "\n",
    "5. Resample that data using the bootstrap method, and compare the fitted models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def f(x,a,b,c):\n",
    "    return c/(1+(a*x - b)**2)\n",
    "\n",
    "# data\n",
    "data = np.array([[1,1],[2,3],[5,7],[0,1],[7,3],[11,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scalability Laws\n",
    "\n",
    "Let m be the number of nodes in a clustered service. And $\\mu$ the throughput of a single node cluster.\n",
    "\n",
    "If there is a fraction $\\sigma$ of the workload that needs to be done serially, then the maximal throughput we can expect is:\n",
    "\n",
    "$$  X(m, \\sigma) = \\mu \\frac{m}{1 + \\sigma (m - 1)}$$\n",
    "\n",
    "This result is known as *Ahmdals Law*.\n",
    "\n",
    "In addition to the serial fraction, most systems require a certain amount of *crosstalk* $\\kappa$ between the\n",
    "nodes, in order to function, in this case the throughput can even degrade with increasing concurrency $m$:\n",
    "\n",
    "$$ X(m, \\sigma, \\kappa) = \\mu \\frac{m}{1 + \\sigma(m-1) + \\kappa m(m-1)} $$\n",
    "\n",
    "This result is known as the *Universal Scalability Law*.\n",
    "\n",
    "Explore: https://www.desmos.com/calculator/pntup6jbhw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the following measurments:\n",
    "\n",
    "```\n",
    "Nodes(m) Throughput(X)\n",
    "======================\n",
    "1       3 req/sec\n",
    "2       5 req/sec\n",
    "5       11 req/sec\n",
    "10      18 req/sec\n",
    "```\n",
    "\n",
    "1. What is the ideal fit for Ahmdals law? What's maximal throughput can we expect? How many nodes do we need?\n",
    "\n",
    "2. What's the idal fit for the USL? What's the maximal throughput we can expect? How many nodes do we need?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
