{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# S2 - Command Line Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## General Remarks\n",
    "- script data access for common tasks (bash, python)\n",
    "- frequent tasks should be a single command\n",
    "- learn a scripting language (C/C++/Java are too verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use UNIX\n",
    "- Rich set of data mangling tools available\n",
    "- Can work with streams (not only files)\n",
    "- Does not hide the details (lilke Windows UIs)\n",
    "- Was designed to do data handling jobs\n",
    "- Pipes to compose tools\n",
    "- E.g. can use ssh to connect to remote servers (get CPU stats from remote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use CSV files\n",
    "- Widely supported (Spreadsheets, Excel, Programming Languages, DBs, GitHub!)\n",
    "- Portable (if you stick to ASCII or utf-8)\n",
    "- Human readable\n",
    "- Good tooling (cat, grep, csvkit)\n",
    "- Can be used like SQL tables (e.g. Join tables for many-many relations)\n",
    "- XML/JSON are describing trees (not lists or tables)\n",
    "- Use compression (zcat or cat | gzip -d to read and | gzip > out.csv)\n",
    "\n",
    "- Use proper csv (not '\\t' separators and the like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling text streams with UNIX tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# cat: print output to stdout\n",
    "# !cat DataSets/LogDB.csv # long output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.13.72 - - [08/May/2015:12:00:00 -0000] \"POST /doc/0 HTTP/1.1\" 200 138 0.155\n",
      "192.168.13.85 - - [08/May/2015:12:00:00 -0000] \"PUT /doc/1 HTTP/1.1\" 200 265 11.933\n",
      "192.168.13.75 - - [08/May/2015:12:00:00 -0000] \"POST /doc/2 HTTP/1.1\" 200 138 1.190\n",
      "192.168.13.85 - - [08/May/2015:12:00:01 -0000] \"PUT /doc/1 HTTP/1.1\" 200 265 34.552\n",
      "192.168.13.13 - - [08/May/2015:12:00:01 -0000] \"GET /doc/3 HTTP/1.1\" 200 4047 0.394\n",
      "192.168.13.13 - - [08/May/2015:12:00:01 -0000] \"GET /doc/4 HTTP/1.1\" 200 795 0.080\n",
      "192.168.13.85 - - [08/May/2015:12:00:01 -0000] \"PUT /doc/1 HTTP/1.1\" 200 265 11.649\n",
      "192.168.13.66 - - [08/May/2015:12:00:01 -0000] \"GET /doc/3 HTTP/1.1\" 200 4047 0.351\n",
      "192.168.13.66 - - [08/May/2015:12:00:01 -0000] \"GET /doc/4 HTTP/1.1\" 200 795 0.068\n",
      "192.168.13.85 - - [08/May/2015:12:00:01 -0000] \"PUT /doc/1 HTTP/1.1\" 200 265 6.433\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Print only first 10 lines\n",
    "# Pipe: connect stdout to stdin stream of next command\n",
    "!cat DataSets/LogDB.out | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Print only first 3 lines\n",
    "!seq 10 | head -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Print the first n-3 lines\n",
    "!seq 10 | head -n-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Last 3 lines\n",
    "!seq 10 | tail -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Last n-3 lines: skip first 2 lines\n",
    "!seq 10 | tail -n+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3335\n"
     ]
    }
   ],
   "source": [
    "# Filter matching lines with grep\n",
    "# Count lines with wc -l\n",
    "!cat DataSets/LogDB.out | grep GET | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## perl -pe\n",
    "\n",
    "```\n",
    "-e: Allows you to provide the program as an argument rather\n",
    "    than in a file. You don't want to have to create a script\n",
    "    file for every little Perl one-liner.\n",
    "\n",
    "-p: Places a printing loop around your command so that it acts on each\n",
    "    line of standard input. Used mostly so Perl can beat the\n",
    "    pants off awk in terms of power AND simplicity :-)\n",
    "        \n",
    "```\n",
    "\n",
    "* Very powerful regular expressions\n",
    "* Sane, widely known syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /doc/0 HTTP/1.1\n",
      "PUT /doc/1 HTTP/1.1\n",
      "POST /doc/2 HTTP/1.1\n",
      "PUT /doc/1 HTTP/1.1\n",
      "GET /doc/3 HTTP/1.1\n",
      "GET /doc/4 HTTP/1.1\n",
      "PUT /doc/1 HTTP/1.1\n",
      "GET /doc/3 HTTP/1.1\n",
      "GET /doc/4 HTTP/1.1\n",
      "PUT /doc/1 HTTP/1.1\n",
      "-p destination: Broken pipe\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "# Parse Log Files with perl -pe\n",
    "!cat DataSets/LogDB.out | perl -pe 's/.*\"(.*)\".*/\\1/' | head\n",
    "\n",
    "\n",
    "# Full csv conversion:\n",
    "# !cat DataSets/LogDB.out | perl -pe 's/^.*\"(.*?) (.*)? (.*)?\" (\\d+) (\\d+) (\\d+.\\d+)$/\\1,\\2,\\4,\\5,\\6/' |  head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## csvkit (http://csvkit.readthedocs.org/en/0.9.1/)\n",
    "\n",
    "* Set of tools to handle csv files at the command line\n",
    "* Python based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----------+---------+---------+---------+---------+----------|\n",
      "|  column1 | column2 | column3 | column4 | column5 | column6  |\n",
      "|----------+---------+---------+---------+---------+----------|\n",
      "|  16      | 6       | 78      | 0       | 0       | 0        |\n",
      "|  5       | 3       | 92      | 0       | 0       | 0        |\n",
      "|  6       | 3       | 91      | 0       | 0       | 0        |\n",
      "|  4       | 2       | 93      | 0       | 0       | 0        |\n",
      "|  4       | 3       | 93      | 0       | 0       | 0        |\n",
      "|  7       | 2       | 91      | 0       | 0       | 0        |\n",
      "|  4       | 2       | 94      | 0       | 0       | 0        |\n"
     ]
    }
   ],
   "source": [
    "# pretty print CSV files with csvlook\n",
    "#\n",
    "# -H no headder row provided\n",
    "!csvlook -H DataSets/cpu.out.csv | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. column1\n",
      "\t<type 'int'>\n",
      "\tNulls: False\n",
      "\tMin: 4\n",
      "\tMax: 88\n",
      "\tSum: 3056\n",
      "\tMean: 30.2574257426\n",
      "\tMedian: 21\n",
      "\tStandard Deviation: 25.0495166908\n",
      "\tUnique values: 50\n",
      "\t5 most frequent values:\n",
      "\t\t5:\t8\n",
      "\t\t16:\t7\n",
      "\t\t27:\t4\n",
      "\t\t20:\t4\n",
      "\t\t7:\t4\n",
      "  2. column2\n",
      "\t<type 'int'>\n",
      "\tNulls: False\n",
      "\tMin: 2\n",
      "\tMax: 15\n",
      "\tSum: 634\n",
      "\tMean: 6.27722772277\n",
      "\tMedian: 6\n",
      "\tStandard Deviation: 3.17826408775\n",
      "\tUnique values: 13\n",
      "\t5 most frequent values:\n",
      "\t\t6:\t17\n",
      "\t\t3:\t14\n",
      "\t\t5:\t14\n",
      "\t\t4:\t10\n",
      "\t\t2:\t9\n",
      "  3. column3\n",
      "\t<type 'int'>\n",
      "\tNulls: False\n",
      "\tMin: 1\n",
      "\tMax: 94\n",
      "\tSum: 6364\n",
      "\tMean: 63.0099009901\n",
      "\tMedian: 72\n",
      "\tStandard Deviation: 27.9693945355\n",
      "\tUnique values: 53\n",
      "\t5 most frequent values:\n",
      "\t\t93:\t5\n",
      "\t\t92:\t5\n",
      "\t\t5:\t4\n",
      "\t\t6:\t4\n",
      "\t\t79:\t4\n",
      "  4. column4\n",
      "\t<type 'int'>\n",
      "\tNulls: False\n",
      "\tValues: 0, 1, 2\n",
      "  5. column5\n",
      "\t<type 'int'>\n",
      "\tNulls: False\n",
      "\tValues: 0\n",
      "  6. column6\n",
      "\t<type 'int'>\n",
      "\tNulls: False\n",
      "\tValues: 0, 1, 2\n",
      "\n",
      "Row count: 101\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics for each column\n",
    "!csvstat -H DataSets/cpu.out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert csv to tsv with quoting\n",
      "\"16\"\t\"6\"\t\"78\"\t\"0\"\t\"0\"\t\"0\"\n",
      "\"5\"\t\"3\"\t\"92\"\t\"0\"\t\"0\"\t\"0\"\n",
      "\"6\"\t\"3\"\t\"91\"\t\"0\"\t\"0\"\t\"0\"\n",
      "\n",
      "\n",
      "Convert back to csv\n",
      "16,6,78,0,0,0\n",
      "5,3,92,0,0,0\n",
      "6,3,91,0,0,0\n"
     ]
    }
   ],
   "source": [
    "# convert between different formats\n",
    "\n",
    "#!csvformat -h\n",
    "\n",
    "# to \"-T\" tab separated output, \"-U 1\" quote all\n",
    "!echo \"Convert csv to tsv with quoting\"\n",
    "!cat DataSets/cpu.out.csv | head -n 3 | csvformat -T -U 1\n",
    "\n",
    "!echo \"\\n\\nConvert back to csv\"\n",
    "!cat DataSets/cpu.out.csv | head -n 3 | csvformat -T -U 1 | csvformat -t -u 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,6,78\n",
      "5,3,92\n",
      "6,3,91\n"
     ]
    }
   ],
   "source": [
    "# Select columns from dataset\n",
    "!cat DataSets/cpu.out.csv | head -n 3 | csvcut -c 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need SQL features?\n",
    "\n",
    "# csfjoin - join two csv tables\n",
    "# csvsql  - import to database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# JSON Handling\n",
    "\n",
    "* jq http://stedolan.github.io/jq/\n",
    "* like xpath, xidel for XML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    1358024400,\n",
      "    1800,\n",
      "    {\n",
      "      \"0.5\": 1,\n",
      "      \"0.59\": 2,\n",
      "      \"1.7\": 1,\n",
      "      \"2.5\": 1,\n",
      "      \"3.4\": 1,\n"
     ]
    }
   ],
   "source": [
    "# pretty print\n",
    "!cat DataSets/HistogramAPI.json | jq '.' | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5,1\n",
      "0.59,2\n",
      "1.7,1\n",
      "10,193\n",
      "100,1\n",
      "11,209\n",
      "12,223\n",
      "120,1\n",
      "13,176\n",
      "14,163\n"
     ]
    }
   ],
   "source": [
    "# Extract Histogram and convert to csv\n",
    "!cat DataSets/HistogramAPI.json | jq '.[0][2] | to_entries | .[] | [.key, .value] | @csv' --raw-output | csvformat -U 0 | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feedgnuplot - Quick plotting from the command line\n",
    "  \n",
    "* https://github.com/dkogan/feedgnuplot\n",
    "\n",
    "* Get plots and histograms on the command line\n",
    "\n",
    "* Real-time plotting od incoming data\n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/Bh6LHikCYAAcLbe.png\">\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" data-cards=\"hidden\" lang=\"en\"><p lang=\"en\" dir=\"ltr\">feedgnuplot totally made my day! <a href=\"https://t.co/9ig6KZ3HQF\">https://t.co/9ig6KZ3HQF</a> Visualizing sensor data from mobile phone via <a href=\"https://twitter.com/hashtag/zeromq?src=hash\">#zeromq</a> done <a href=\"http://t.co/z9ipK3EQhA\">pic.twitter.com/z9ipK3EQhA</a></p>&mdash; Heinrich Hartmann (@HeinrichHartman) <a href=\"https://twitter.com/HeinrichHartman/status/440942775173799936\">March 4, 2014</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
